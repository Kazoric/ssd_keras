{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD512 Inference Tutorial\n",
    "\n",
    "This is a brief tutorial that shows how to use a trained SSD512 for inference on the Pascal VOC datasets. It is the same as the SSD300 inference tutorial but with all parameters preset for SSD512 for Pascal VOC. If you'd like more detailed explanations on how to use the model generally, please refer to [`ssd300_training.ipynb`](https://github.com/pierluigiferrari/ssd_keras/blob/master/ssd300_training.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssd512 import ssd_512\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from exif import Image\n",
    "\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the image size.\n",
    "img_height = 512\n",
    "img_width = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load a trained SSD\n",
    "\n",
    "Either load a trained model or build a model and load trained weights into it. Since the HDF5 files I'm providing contain only the weights for the various SSD versions, not the complete models, you'll have to go with the latter option when using this implementation for the first time. You can then of course save the model and next time load the full model directly, without having to build it.\n",
    "\n",
    "You can find the download links to all the trained model weights in the README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Build the model and load trained weights into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1: Build the Keras model\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = ssd_512(image_size=(img_height, img_width, 3),\n",
    "                n_classes=20,\n",
    "                mode='inference',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=[0.07, 0.15, 0.3, 0.45, 0.6, 0.75, 0.9, 1.05], # The scales for MS COCO are [0.04, 0.1, 0.26, 0.42, 0.58, 0.74, 0.9, 1.06]\n",
    "                aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5]],\n",
    "               two_boxes_for_ar1=True,\n",
    "               steps=[8, 16, 32, 64, 128, 256, 512],\n",
    "               offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "               clip_boxes=False,\n",
    "               variances=[0.1, 0.1, 0.2, 0.2],\n",
    "               normalize_coords=True,\n",
    "               subtract_mean=[123, 117, 104],\n",
    "               swap_channels=[2, 1, 0],\n",
    "               confidence_thresh=0.5,\n",
    "               iou_threshold=0.45,\n",
    "               top_k=200,\n",
    "               nms_max_output_size=400)\n",
    "\n",
    "# 2: Load the trained weights into the model.\n",
    "\n",
    "# TODO: Set the path of the trained weights.\n",
    "weights_path = 'path/to/trained/weights/VGG_VOC0712_SSD_512x512_iter_120000.h5'\n",
    "\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "# 3: Compile the model so that Keras won't complain the next time you load it.\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Load a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Set the path to the `.h5` file of the model to be loaded.\n",
    "model_path = R'path/to/trained/model.h5'\n",
    "\n",
    "# We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, n_neg_min=0, alpha=1.0)\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "                                               'L2Normalization': L2Normalization,\n",
    "                                               'DecodeDetections': DecodeDetections,\n",
    "                                               'compute_loss': ssd_loss.compute_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load some images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images should not have any orientation in the file metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = R'path/'\n",
    "\n",
    "fichiers = [f for f in listdir(image_path) if isfile(join(image_path, f))]\n",
    "\n",
    "for file in fichiers:\n",
    "    with open(image_path + '\\\\' + file, 'rb') as image_file:\n",
    "        my_image = Image(image_file)\n",
    "\n",
    "    if 'orientation' in my_image.list_all():\n",
    "        del my_image.orientation\n",
    "\n",
    "    with open(image_path + '\\\\' + file, 'wb') as new_image_file:\n",
    "        new_image_file.write(my_image.get_file())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some images for which you'd like the model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_path = R'path/'\n",
    "\n",
    "fichiers = [f for f in listdir(image_path) if isfile(join(image_path, f))]\n",
    "\n",
    "orig_images = [] # Store the images here.\n",
    "input_images = [] # Store resized versions of the images here.\n",
    "\n",
    "for file in fichiers:\n",
    "    img_path = image_path + '\\\\' + file\n",
    "    orig_images.append(imread(img_path))\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img = image.img_to_array(img) \n",
    "    input_images.append(img)\n",
    "    \n",
    "input_images = np.array(input_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make and visualize predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`y_pred` contains a fixed number of predictions per batch item (200 if you use the original model configuration), many of which are low-confidence predictions or dummy entries. We therefore need to apply a confidence threshold to filter out the bad predictions. Set this confidence threshold value how you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_time = time.time()\n",
    "\n",
    "# Makes predictions on images\n",
    "y_pred = model.predict(input_images)\n",
    "print(\"--- Pred time : %s seconds ---\" % (time.time() - pred_time))\n",
    "\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, 3)).tolist()\n",
    "colors = ['black', 'red', 'blue']\n",
    "classes = ['background',\n",
    "           'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "           'bottle', 'bus', 'car', 'cat',\n",
    "           'chair', 'cow', 'diningtable', 'dog',\n",
    "           'horse', 'motorbike', 'person', 'pottedplant',\n",
    "           'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "time_list = []\n",
    "\n",
    "for i in range(len(orig_images)):\n",
    "    image_time = time.time()\n",
    "    # Decode the predictions\n",
    "    y_pred_decoded = decode_detections(y_pred, confidence_thresh=0.5, iou_threshold=0.5, top_k=1000, normalize_coords=True, img_height=orig_images[i].shape[0], img_width=orig_images[i].shape[1])\n",
    "    time_list.append(time.time() - image_time)\n",
    "    print(\"--- Image\", i, \" time %s seconds ---\" % (time.time() - image_time))\n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.imshow(orig_images[i])\n",
    "\n",
    "    current_axis = plt.gca()\n",
    "    for box in y_pred_decoded[i]:\n",
    "        xmin = box[2]\n",
    "        ymin = box[3]\n",
    "        xmax = box[4]\n",
    "        ymax = box[5]\n",
    "        color = colors[round(box[0])]\n",
    "        label = '{}: {:.2f}'.format(classes[round(box[0])], box[1])\n",
    "        current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color=color, fill=False, linewidth=2))\n",
    "        current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor':color, 'alpha':1.0})\n",
    "    plt.show()\n",
    "\n",
    "print(\"--- Global time : %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "78ddfc3686b8b7161f2836984651df038ec9a0366954334fc42499f59ad2b3c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
