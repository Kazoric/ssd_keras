{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    root_path = \"path/\"\n",
    "\n",
    "    # list all jpg and xml files\n",
    "    images_temp_list = []\n",
    "    xml_files_temp_list = []\n",
    "\n",
    "    for file in os.listdir(root_path):\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".JPG\"):\n",
    "            images_temp_list.append(os.path.join(root_path, file))\n",
    "        elif file.endswith(\".xml\"):\n",
    "            xml_files_temp_list.append(os.path.join(root_path, file))\n",
    "\n",
    "    print(len(images_temp_list), images_temp_list[0])\n",
    "    print(len(xml_files_temp_list), xml_files_temp_list[0])\n",
    "\n",
    "    images_list = []\n",
    "    xml_files_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # take only jpeg files with corresponding xml file\n",
    "    # and take only classes of your choice\n",
    "    class_filter = ['ticket']\n",
    "    #class_filter = ['temoin:0', 'temoin:25', 'temoin:50', 'temoin:75', 'temoin90', 'temoin:95', 'temoin:100']\n",
    "    min_size_filter = 300\n",
    "    for xml_file_path in xml_files_temp_list:\n",
    "        xml_path_chopped = xml_file_path.split('.')[0]\n",
    "        #print(xml_file_path)\n",
    "        with open(os.path.join(xml_file_path)) as f:\n",
    "            soup = BeautifulSoup(f, 'xml')\n",
    "\n",
    "        folder = soup.folder.text\n",
    "        w = int(soup.find('width').text)\n",
    "        h = int(soup.find('height').text)\n",
    "\n",
    "        if w < min_size_filter or h < min_size_filter:\n",
    "            continue\n",
    "\n",
    "        # Get a list of all objects in this image.\n",
    "        objects = soup.find_all('object')\n",
    "\n",
    "        # for obj in objects:\n",
    "        #     class_name = obj.find('name', recursive=False).text\n",
    "        #     if class_name in class_filter:\n",
    "        #         if xml_path_chopped + '.jpg' in images_temp_list:\n",
    "        #             images_list.append(xml_path_chopped + '.jpg')\n",
    "        #             xml_files_list.append(xml_file_path)\n",
    "        #             labels_list.append(class_name)\n",
    "\n",
    "        # class_name = 'ticket'\n",
    "        # if class_name in class_filter:\n",
    "        #     if xml_path_chopped + '.jpg' in images_temp_list:\n",
    "        #         images_list.append(xml_path_chopped + '.jpg')\n",
    "        #         xml_files_list.append(xml_file_path)\n",
    "        #         labels_list.append(class_name)\n",
    "\n",
    "        class_name = objects[0].find('name', recursive=False).text\n",
    "        if xml_path_chopped + '.JPG' in images_temp_list:\n",
    "            images_list.append(xml_path_chopped + '.jpg')\n",
    "            xml_files_list.append(xml_file_path)\n",
    "            labels_list.append(class_name)\n",
    "\n",
    "    print(len(images_list), images_list[0])\n",
    "    print(len(xml_files_list), xml_files_list[0])\n",
    "    \"\"\"\n",
    "    with open(os.path.join(root_path, \"image_names.txt\"), \"w+\") as file_writer:\n",
    "        for image_path in images_list:\n",
    "            image_name_chopped = image_path.split('.')[0].split(\"\\\\\")[-1]\n",
    "            file_writer.write(\"%s\\n\" % image_name_chopped)\n",
    "    \"\"\"\n",
    "\n",
    "    # randomly take a percentage as training set\n",
    "\n",
    "    train_images_list, val_images_list, labels_train, labels_test = train_test_split(images_list, labels_list, test_size=0.98, random_state=42, shuffle=True)\n",
    "\n",
    "    print(len(train_images_list), train_images_list[0])\n",
    "    print(len(val_images_list), val_images_list[0])\n",
    "    # write the names in one file per set\n",
    "    with open(os.path.join(root_path, \"image_names_train.txt\"), \"w+\") as file_writer:\n",
    "        for image_path in train_images_list:\n",
    "            image_name_chopped = image_path.split('.')[0].split(\"\\\\\")[-1]\n",
    "            file_writer.write(\"%s\\n\" % image_name_chopped)\n",
    "\n",
    "    with open(os.path.join(root_path, \"image_names_val.txt\"), \"w+\") as file_writer:\n",
    "        for image_path in val_images_list:\n",
    "            image_name_chopped = image_path.split('.')[0].split(\"\\\\\")[-1]\n",
    "            file_writer.write(\"%s\\n\" % image_name_chopped)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8d2843078936055482f322f59f6556f9be76f4c2bdebe10db05c928f1d00891"
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
